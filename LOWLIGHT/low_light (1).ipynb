{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YolHIkUEMhnn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jED4-lX-MlMx",
        "outputId": "5358ad4e-7ae2-4882-918d-e793e132f4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "_Glyc8bCMoPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/LOWLIGHT/\")"
      ],
      "metadata": {
        "id": "9lpc0NrfNNzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_dR5ADnnyxeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python Generate_Patches_Lowlight.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWJMYKWKNXCS",
        "outputId": "2921ac3f-f298-4ed2-dd68-547e737a8f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "number of training data 485\n",
            "total patches = 1022880 , batch size = 32, total batches = 31965\n",
            "2\n",
            "1\n",
            "7\n",
            "4\n",
            "5\n",
            "size of inputs tensor = (1022880, 30, 30, 3)\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Generate_Patches_Lowlight.py"
      ],
      "metadata": {
        "id": "iOw4GJgoRG78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f80df8a-3c65-46de-fee9-e2f378b7c949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'Generate_Patches_Lowlight.py': [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Calculate the patch size\n",
        "#patch_width = image_width // int(np.sqrt(num_patches))\n",
        "#patch_height = image_height // (num_patches // int(np.sqrt(num_patches)))\n",
        "\n",
        "scales = [1.0]  # Only one scale since you want non-overlapping patches\n",
        "step = 0\n",
        "stride = 30 # Since patches are non-overlapping, stride is equal to patch height\n",
        "pat_size = 30\n",
        "batch_size=32\n",
        "\n",
        "# Define scales, step, stride, batch_size, pat_size, save_dir, and genDataPath\n",
        "\n",
        "# Define a list of image folders for low-light and high-light images\n",
        "lowLightDataPath = '/content/drive/MyDrive/LOWLIGHT/lol_dataset/our485/low/'\n",
        "highLightDataPath ='/content/drive/MyDrive/LOWLIGHT/lol_dataset/our485/high/'\n",
        "# Function to generate patches and save them\n",
        "def generate_and_save_patches(image_paths, save_folder):\n",
        "    imgArray = []\n",
        "    for path in image_paths:\n",
        "        imgArray.append(cv2.imread(str(path)))\n",
        "\n",
        "    print('lenImages', len(imgArray))\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, (im_h - pat_size), stride):\n",
        "                for y in range(0 + step, (im_w - pat_size), stride):\n",
        "                    count += 1\n",
        "\n",
        "    origin_patch_num = count\n",
        "    if origin_patch_num % batch_size != 0:\n",
        "        numPatches = (origin_patch_num // batch_size + 1) * batch_size\n",
        "    else:\n",
        "        numPatches = origin_patch_num\n",
        "\n",
        "    print('total patches=%d, batch_size=%d, total_batches=%d' % (numPatches, batch_size, numPatches // batch_size))\n",
        "\n",
        "    inputs = np.zeros((int(numPatches), int(pat_size), int(pat_size), 3), dtype=np.uint8)\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, im_h - pat_size, stride):\n",
        "                for y in range(0 + step, im_w - pat_size, stride):\n",
        "                    inputs[count, :, :, :] = img_s[x:x + pat_size, y:y + pat_size, :]\n",
        "                    count += 1\n",
        "\n",
        "    if count < numPatches:\n",
        "        to_pad = int(numPatches - count)\n",
        "        inputs[-to_pad:, :, :, :] = inputs[:to_pad, :, :, :]\n",
        "\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.mkdir(save_folder)\n",
        "\n",
        "    np.save(os.path.join(save_folder, \"image_patches_1\"), inputs)\n",
        "\n",
        "# Generate and save patches for low-light images\n",
        "lowLightPaths = sorted(list(Path(lowLightDataPath).glob('./*.png')))\n",
        "generate_and_save_patches(lowLightPaths,'/content/drive/MyDrive/LOWLIGHT/data//low')\n",
        "\n",
        "# Generate and save patches for high-light images\n",
        "highLightPaths = sorted(list(Path(highLightDataPath).glob('./*.png')))\n",
        "generate_and_save_patches(highLightPaths, '/content/drive/MyDrive/LOWLIGHT/data/high')\n",
        "\n"
      ],
      "metadata": {
        "id": "R2v6jEBYy2G6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dec5d2d-d220-43f0-9bec-ea4699547cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenImages 485\n",
            "total patches=119808, batch_size=32, total_batches=3744\n",
            "lenImages 485\n",
            "total patches=119808, batch_size=32, total_batches=3744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "image_width = 600\n",
        "image_height = 400\n",
        "num_patches = 16\n",
        "\n",
        "# Calculate the patch size\n",
        "#patch_width = image_width // int(np.sqrt(num_patches))\n",
        "#patch_height = image_height // (num_patches // int(np.sqrt(num_patches)))\n",
        "\n",
        "scales = [1.0]  # Only one scale since you want non-overlapping patches\n",
        "step = 0\n",
        "stride = 10 # Since patches are non-overlapping, stride is equal to patch height\n",
        "pat_size = 30\n",
        "batch_size=32\n",
        "\n",
        "# Define scales, step, stride, batch_size, pat_size, save_dir, and genDataPath\n",
        "\n",
        "# Define a list of image folders for low-light and high-light images\n",
        "lowLightDataPath = '/content/drive/MyDrive/LOWLIGHT/lol_dataset/our485/low/'\n",
        "highLightDataPath ='/content/drive/MyDrive/LOWLIGHT/lol_dataset/our485/high/'\n",
        "# Function to generate patches and save them\n",
        "def generate_and_save_patches(image_paths, save_folder):\n",
        "    imgArray = []\n",
        "    for path in image_paths:\n",
        "        imgArray.append(cv2.imread(str(path)))\n",
        "\n",
        "    print('lenImages', len(imgArray))\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, (im_h - pat_size), stride):\n",
        "                for y in range(0 + step, (im_w - pat_size), stride):\n",
        "                    count += 1\n",
        "\n",
        "    origin_patch_num = count\n",
        "    if origin_patch_num % batch_size != 0:\n",
        "        numPatches = (origin_patch_num // batch_size + 1) * batch_size\n",
        "    else:\n",
        "        numPatches = origin_patch_num\n",
        "\n",
        "    print('total patches=%d, batch_size=%d, total_batches=%d' % (numPatches, batch_size, numPatches // batch_size))\n",
        "\n",
        "    inputs = np.zeros((int(numPatches), int(pat_size), int(pat_size), 3), dtype=np.uint8)\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, im_h - pat_size, stride):\n",
        "                for y in range(0 + step, im_w - pat_size, stride):\n",
        "                    inputs[count, :, :, :] = img_s[x:x + pat_size, y:y + pat_size, :]\n",
        "                    count += 1\n",
        "\n",
        "    if count < numPatches:\n",
        "        to_pad = int(numPatches - count)\n",
        "        inputs[-to_pad:, :, :, :] = inputs[:to_pad, :, :, :]\n",
        "\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.mkdir(save_folder)\n",
        "\n",
        "    np.save(os.path.join(save_folder, \"image_patche_1\"), inputs)\n",
        "\n",
        "# Generate and save patches for low-light images\n",
        "                                                           #           lowLightPaths = sorted(list(Path(lowLightDataPath).glob('./*.png')))\n",
        "                                               #                       generate_and_save_patches(lowLightPaths,'/content/drive/MyDrive/LOWLIGHT/data/low.npy')\n",
        "\n",
        "# Generate and save patches for high-light images\n",
        "highLightPaths = sorted(list(Path(highLightDataPath).glob('./*.png')))\n",
        "generate_and_save_patches(highLightPaths, '/content/drive/MyDrive/LOWLIGHT/data/high')\n",
        "\n"
      ],
      "metadata": {
        "id": "PPenqz6kThDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd07e42c-a847-4a42-abd5-f33fd34f5bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenImages 495\n",
            "total patches=1043968, batch_size=32, total_batches=32624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "image_width = 600\n",
        "image_height = 400\n",
        "num_patches = 16\n",
        "\n",
        "# Calculate the patch size\n",
        "#patch_width = image_width // int(np.sqrt(num_patches))\n",
        "#patch_height = image_height // (num_patches // int(np.sqrt(num_patches)))\n",
        "\n",
        "scales = [1.0]  # Only one scale since you want non-overlapping patches\n",
        "step = 0\n",
        "stride = 10 # Since patches are non-overlapping, stride is equal to patch height\n",
        "pat_size = 30\n",
        "batch_size=32\n",
        "\n",
        "# Define scales, step, stride, batch_size, pat_size, save_dir, and genDataPath\n",
        "\n",
        "# Define a list of image folders for low-light and high-light images\n",
        "lowLightDataPath = '/content/drive/MyDrive/LOWLIGHT/lol_dataset/our485/low/'\n",
        "highLightDataPath ='/content/drive/MyDrive/LOWLIGHT/lol_dataset/our485/high/'\n",
        "# Function to generate patches and save them\n",
        "def generate_and_save_patches(image_paths, save_folder):\n",
        "    imgArray = []\n",
        "    for path in image_paths:\n",
        "        imgArray.append(cv2.imread(str(path)))\n",
        "\n",
        "    print('lenImages', len(imgArray))\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, (im_h - pat_size), stride):\n",
        "                for y in range(0 + step, (im_w - pat_size), stride):\n",
        "                    count += 1\n",
        "\n",
        "    origin_patch_num = count\n",
        "    if origin_patch_num % batch_size != 0:\n",
        "        numPatches = (origin_patch_num // batch_size + 1) * batch_size\n",
        "    else:\n",
        "        numPatches = origin_patch_num\n",
        "\n",
        "    print('total patches=%d, batch_size=%d, total_batches=%d' % (numPatches, batch_size, numPatches // batch_size))\n",
        "\n",
        "    inputs = np.zeros((int(numPatches), int(pat_size), int(pat_size), 3), dtype=np.uint8)\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, im_h - pat_size, stride):\n",
        "                for y in range(0 + step, im_w - pat_size, stride):\n",
        "                    inputs[count, :, :, :] = img_s[x:x + pat_size, y:y + pat_size, :]\n",
        "                    count += 1\n",
        "\n",
        "    if count < numPatches:\n",
        "        to_pad = int(numPatches - count)\n",
        "        inputs[-to_pad:, :, :, :] = inputs[:to_pad, :, :, :]\n",
        "\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.mkdir(save_folder)\n",
        "\n",
        "    np.save(os.path.join(save_folder, \"image_patches\"), inputs)\n",
        "\n",
        "# Generate and save patches for low-light images\n",
        "lowLightPaths = sorted(list(Path(lowLightDataPath).glob('./*.png')))\n",
        "generate_and_save_patches(lowLightPaths,'/content/drive/MyDrive/LOWLIGHT/data/low')\n",
        "\n",
        "# Generate and save patches for high-light images\n",
        "#highLightPaths = sorted(list(Path(highLightDataPath).glob('./*.png')))\n",
        "#generate_and_save_patches(highLightPaths, '/content/drive/MyDrive/LOWLIGHT/data/high.npy')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH80-NkMqKZI",
        "outputId": "fbe7c436-2402-4055-8e91-f3284a03af94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenImages 485\n",
            "total patches=1022880, batch_size=32, total_batches=31965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Calculate the patch size\n",
        "#patch_width = image_width // int(np.sqrt(num_patches))\n",
        "#patch_height = image_height // (num_patches // int(np.sqrt(num_patches)))\n",
        "\n",
        "scales = [1.0]  # Only one scale since you want non-overlapping patches\n",
        "step = 0\n",
        "stride = 30 # Since patches are non-overlapping, stride is equal to patch height\n",
        "pat_size = 30\n",
        "batch_size=32\n",
        "\n",
        "# Define scales, step, stride, batch_size, pat_size, save_dir, and genDataPath\n",
        "\n",
        "# Define a list of image folders for low-light and high-light images\n",
        "lowLightDataPath = '/home2/devanand_2001cs19/lowlight/lol_dataset/ours485/low/'\n",
        "highLightDataPath ='/home2/devanand_2001cs19/lowlight/lol_dataset/ours485/high/'\n",
        "# Function to generate patches and save them\n",
        "def generate_and_save_patches(image_paths, save_folder):\n",
        "    imgArray = []\n",
        "    for path in image_paths:\n",
        "        imgArray.append(cv2.imread(str(path)))\n",
        "\n",
        "    print('lenImages', len(imgArray))\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, (im_h - pat_size), stride):\n",
        "                for y in range(0 + step, (im_w - pat_size), stride):\n",
        "                    count += 1\n",
        "\n",
        "    origin_patch_num = count\n",
        "    if origin_patch_num % batch_size != 0:\n",
        "        numPatches = (origin_patch_num // batch_size + 1) * batch_size\n",
        "    else:\n",
        "        numPatches = origin_patch_num\n",
        "\n",
        "    print('total patches=%d, batch_size=%d, total_batches=%d' % (numPatches, batch_size, numPatches // batch_size))\n",
        "\n",
        "    inputs = np.zeros((int(numPatches), int(pat_size), int(pat_size), 3), dtype=np.uint8)\n",
        "\n",
        "    count = 0\n",
        "    for i in range(len(imgArray)):\n",
        "        img = imgArray[i]\n",
        "        for s in scales:\n",
        "            newsize = (int(img.shape[0] * s), int(img.shape[1] * s))\n",
        "            img_s = cv2.resize(img, newsize, interpolation=cv2.INTER_CUBIC)\n",
        "            im_h, im_w, _ = img_s.shape\n",
        "            for x in range(0 + step, im_h - pat_size, stride):\n",
        "                for y in range(0 + step, im_w - pat_size, stride):\n",
        "                    inputs[count, :, :, :] = img_s[x:x + pat_size, y:y + pat_size, :]\n",
        "                    count += 1\n",
        "\n",
        "    if count < numPatches:\n",
        "        to_pad = int(numPatches - count)\n",
        "        inputs[-to_pad:, :, :, :] = inputs[:to_pad, :, :, :]\n",
        "\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.mkdir(save_folder)\n",
        "\n",
        "    np.save(os.path.join(save_folder, \"image_patches\"), inputs)\n",
        "\n",
        "# Generate and save patches for low-light images\n",
        "lowLightPaths = sorted(list(Path(lowLightDataPath).glob('./*.png')))\n",
        "generate_and_save_patches(lowLightPaths,'/home2/devanand_2001cs19/lowlight/data1/low')\n",
        "\n",
        "# Generate and save patches for high-light images\n",
        "highLightPaths = sorted(list(Path(highLightDataPath).glob('./*.png')))\n",
        "generate_and_save_patches(highLightPaths, '/home2/devanand_2001cs19/lowlight/data1/high')\n",
        "\n"
      ],
      "metadata": {
        "id": "A2IM9QzMHDcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ENLTN.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjBIgOWNNyXY",
        "outputId": "8a685bea-684a-4867-b316-eb6b671dc2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-11 19:31:53.721583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-11 19:31:53.721634: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-11 19:31:53.722955: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-11 19:31:53.730246: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-11 19:31:55.011920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-11 19:31:57.334604: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2024-03-11 19:31:57.334663: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: ca3f9d231453\n",
            "2024-03-11 19:31:57.334681: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: ca3f9d231453\n",
            "2024-03-11 19:31:57.334796: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.104.5\n",
            "2024-03-11 19:31:57.334832: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.104.5\n",
            "2024-03-11 19:31:57.334846: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.104.5\n",
            "1\n",
            "uint8\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import myconfig as config\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Conv2D,Activation,Input,Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
        "tf_device='/gpu:6'\n",
        "# create CNN model\n",
        "input_img=Input(shape=(None,None,3))\n",
        "\n",
        "log_img = tf.math.log1p(input_img)\n",
        "x1u = 1 - log_img\n",
        "#x1u=tf.math.log(input_img)\n",
        "\n",
        "x2u=Conv2D(32,(3,3),padding=\"same\")(x1u)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x2u)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(xu)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com1u = Add()([x2u, xu])\n",
        "\n",
        "x3u=Conv2D(32,(3,3),padding=\"same\")(x_com1u)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x3u)\n",
        "x41u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x3u)\n",
        "x42u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x3u)\n",
        "x43u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com2u = Add()([x41u, x42u])\n",
        "x_com3u = Add()([x41u, x43u])\n",
        "x_com4u = Add()([x42u, x43u])\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com2u)\n",
        "x51u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com3u)\n",
        "x52u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com4u)\n",
        "x53u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com5u = Add()([x51u, x52u])\n",
        "x_com6u = Add()([x_com5u, x53u])\n",
        "\n",
        "xu=Conv2D(3,(3,3),padding=\"same\")(x_com6u)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com7u = Add()([x1u, xu])\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com7u)\n",
        "#xupper = tf.math.exp(xu)\n",
        "xupper = 1 - tf.math.exp(-1 * xu)\n",
        "\n",
        "x1u=input_img\n",
        "\n",
        "x2u=Conv2D(32,(3,3),padding=\"same\")(x1u)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x2u)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(xu)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com1u = Add()([x2u, xu])\n",
        "\n",
        "x3u=Conv2D(32,(3,3),padding=\"same\")(x_com1u)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x3u)\n",
        "x41u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x3u)\n",
        "x42u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x3u)\n",
        "x43u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com2u = Add()([x41u, x42u])\n",
        "x_com3u = Add()([x41u, x43u])\n",
        "x_com4u = Add()([x42u, x43u])\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com2u)\n",
        "x51u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com3u)\n",
        "x52u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com4u)\n",
        "x53u=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com5u = Add()([x51u, x52u])\n",
        "x_com6u = Add()([x_com5u, x53u])\n",
        "\n",
        "xu=Conv2D(3,(3,3),padding=\"same\")(x_com6u)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com7u = Add()([x1u, xu])\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(x_com7u)\n",
        "xlower = xu\n",
        "\n",
        "x_com8 = Add()([xupper, xlower])\n",
        "xm1 =Conv2D(32,(3,3),padding=\"same\")(x_com8)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(xm1)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "xu=Conv2D(32,(3,3),padding=\"same\")(xu)\n",
        "xu=Activation('LeakyReLU')(xu)\n",
        "\n",
        "x_com9 = Add()([xm1, xu])\n",
        "\n",
        "xfinal=Conv2D(3,(3,3),padding=\"same\")(x_com9)\n",
        "\n",
        "model = Model(inputs=input_img, outputs=xfinal)"
      ],
      "metadata": {
        "id": "1gaF07EOTJjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# load the data and normalize it\n",
        "data1='/content/drive/MyDrive/LOWLIGHT/data/high/image_patches_1.npy'\n",
        "highResImages = np.load(data1)\n",
        "#path to training data\n",
        "data='/content/drive/MyDrive/LOWLIGHT/data/low/image_patches_1.npy'\n",
        "# Load the low-resolution images\n",
        "lowResImages = np.load(data)\n",
        "\n",
        "# Normalize the pixel values for both sets of images (if necessary)\n",
        "# You can use min-max scaling to normalize to the range [0, 1]\n",
        "highResImages = highResImages / 255.0\n",
        "lowResImages = lowResImages / 255.0\n",
        "\n",
        "# Convert the pixel data type to float32 (if not already)\n",
        "highImages = highResImages.astype('float32')\n",
        "lowImages = lowResImages.astype('float32')\n",
        "\n",
        "# define augmentor and create custom flow\n",
        "aug = ImageDataGenerator(rotation_range=30, fill_mode=\"nearest\")\n",
        "def myFlow(generator,X,Y):\n",
        "    for batchhigh, batchlow in generator.flow(x=X,y=Y,batch_size=config.batch_size,seed=0):\n",
        "        yield (batchlow,batchhigh)\n",
        "\n",
        "# create custom learning rate scheduler\n",
        "def lr_decay(epoch):\n",
        "    initAlpha=0.001\n",
        "    factor=0.5\n",
        "    dropEvery=5\n",
        "    alpha=initAlpha*(factor ** np.floor((1+epoch)/dropEvery))\n",
        "    return float(alpha)\n",
        "callbacks=[LearningRateScheduler(lr_decay)]\n",
        "\n",
        "# create custom loss, compile the model\n",
        "print(\"[INFO] compilingTheModel\")\n",
        "#opt=optimizers.Adam(lr=0.001)\n",
        "#def custom_loss(y_true,y_pred):\n",
        "#    diff=y_true-y_pred\n",
        "#    res=K.sum(diff*diff)/(2*config.batch_size)\n",
        "#    return res\n",
        "\n",
        "opt=optimizers.Adam(learning_rate=0.0001)\n",
        "def custom_loss(y_true,y_pred):\n",
        "    diff=K.abs(y_true-y_pred)\n",
        "    l1=(diff)/(config.batch_size)\n",
        "    return l1\n",
        "model.compile(loss=custom_loss,optimizer=opt)\n",
        "\n",
        "# train\n",
        "model.fit_generator(myFlow(aug,highImages,lowImages),\n",
        "epochs=config.epochs,steps_per_epoch=len(highImages)//config.batch_size,callbacks=callbacks,verbose=1)\n",
        "\n",
        "# save the model\n",
        "model.save('EnlightenNet.h5')"
      ],
      "metadata": {
        "id": "t-mgvLg5i3pW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "92b39f99-ccad-4185-98c9-1ffe318fa77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] compilingTheModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-97930ee2c45e>:49: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(myFlow(aug,highImages,lowImages),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 984/3744 [======>.......................] - ETA: 43:42 - loss: 0.0044"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-97930ee2c45e>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m model.fit_generator(myFlow(aug,highImages,lowImages),\n\u001b[0m\u001b[1;32m     50\u001b[0m epochs=config.epochs,steps_per_epoch=len(highImages)//config.batch_size,callbacks=callbacks,verbose=1)\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/LOWLIGHT/EnlightenNet_1_pat30_s30.h5')"
      ],
      "metadata": {
        "id": "A_Qe_KLMIish"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the saved model\n",
        "from tensorflow.keras.models import load_model\n",
        "# create custom loss, compile the model\n",
        "\n",
        "# load the data and normalize it\n",
        "data1='/content/drive/MyDrive/LOWLIGHT/data/high/image_patches.npy'\n",
        "highResImages = np.load(data1)\n",
        "#path to training data\n",
        "data='/content/drive/MyDrive/LOWLIGHT/data/low/image_patches.npy'\n",
        "# Load the low-resolution images\n",
        "lowResImages = np.load(data)\n",
        "\n",
        "# Normalize the pixel values for both sets of images (if necessary)\n",
        "# You can use min-max scaling to normalize to the range [0, 1]\n",
        "highResImages = highResImages / 255.0\n",
        "lowResImages = lowResImages / 255.0\n",
        "\n",
        "# Convert the pixel data type to float32 (if not already)\n",
        "highImages = highResImages.astype('float32')\n",
        "lowImages = lowResImages.astype('float32')\n",
        "\n",
        "# define augmentor and create custom flow\n",
        "aug = ImageDataGenerator(rotation_range=30, fill_mode=\"nearest\")\n",
        "def myFlow(generator,X,Y):\n",
        "    for batchhigh, batchlow in generator.flow(x=X,y=Y,batch_size=config.batch_size,seed=0):\n",
        "        yield (batchlow,batchhigh)\n",
        "\n",
        "# create custom learning rate scheduler\n",
        "def lr_decay(epoch):\n",
        "    initAlpha=0.001\n",
        "    factor=0.5\n",
        "    dropEvery=5\n",
        "    alpha=initAlpha*(factor ** np.floor((1+epoch)/dropEvery))\n",
        "    return float(alpha)\n",
        "callbacks=[LearningRateScheduler(lr_decay)]\n",
        "#opt=optimizers.Adam(lr=0.001)\n",
        "#def custom_loss(y_true,y_pred):\n",
        "#    diff=y_true-y_pred\n",
        "#    res=K.sum(diff*diff)/(2*config.batch_size)\n",
        "#    return res\n",
        "\n",
        "opt=optimizers.Adam(learning_rate=0.0001)\n",
        "def custom_loss(y_true,y_pred):\n",
        "    diff=K.abs(y_true-y_pred)\n",
        "    l1=(diff)/(config.batch_size)\n",
        "    return l1\n",
        "model.compile(loss=custom_loss,optimizer=opt)\n",
        "saved_model_path = '/content/drive/MyDrive/LOWLIGHT/EnlightenNet_40.h5'\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load_model(saved_model_path, custom_objects={'custom_loss': custom_loss})\n",
        "# create custom loss, compile the model\n",
        "print(\"[INFO] compilingTheModel\")\n",
        "#opt=optimizers.Adam(lr=0.001)\n",
        "#def custom_loss(y_true,y_pred):\n",
        "#    diff=y_true-y_pred\n",
        "#    res=K.sum(diff*diff)/(2*config.batch_size)\n",
        "#    return res\n",
        "\n",
        "opt=optimizers.Adam(learning_rate=0.0001)\n",
        "def custom_loss(y_true,y_pred):\n",
        "    diff=K.abs(y_true-y_pred)\n",
        "    l1=(diff)/(config.batch_size)\n",
        "    return l1\n",
        "model.compile(loss=custom_loss,optimizer=opt)\n",
        "\n",
        "# train\n",
        "model.fit_generator(myFlow(aug,highImages,lowImages),\n",
        "epochs=10,steps_per_epoch=len(highImages)//config.batch_size,callbacks=callbacks,verbose=1)"
      ],
      "metadata": {
        "id": "Q5Q8u7qICsfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save('/content/drive/MyDrive/LOWLIGHT/EnlightenNet_50.h5')"
      ],
      "metadata": {
        "id": "nwlikAAIy5mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ssim(img1, img2):\n",
        "    C1 = (0.01 * 255)**2\n",
        "    C2 = (0.03 * 255)**2\n",
        "\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
        "                                                            (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()\n",
        "\n",
        "def calculate_ssim(img1, img2, border=0):\n",
        "    '''calculate SSIM\n",
        "    the same outputs as MATLAB's\n",
        "    img1, img2: [0, 255]\n",
        "    '''\n",
        "    #img1 = img1.squeeze()\n",
        "    #img2 = img2.squeeze()\n",
        "    if not img1.shape == img2.shape:\n",
        "        raise ValueError('Input images must have the same dimensions.')\n",
        "    h, w = img1.shape[:2]\n",
        "    img1 = img1[border:h - border, border:w - border]\n",
        "    img2 = img2[border:h - border, border:w - border]\n",
        "\n",
        "    if img1.ndim == 2:\n",
        "        return ssim(img1, img2)\n",
        "    elif img1.ndim == 3:\n",
        "        if img1.shape[2] == 3:\n",
        "            ssims = []\n",
        "            for i in range(3):\n",
        "                ssims.append(ssim(img1[:, :, i], img2[:, :, i]))\n",
        "            return np.array(ssims).mean()\n",
        "        elif img1.shape[2] == 1:\n",
        "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
        "    else:\n",
        "        raise ValueError('Wrong input image dimensions.')"
      ],
      "metadata": {
        "id": "zWsrUCNnyJOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def psnr1(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')  # PSNR is infinite if images are identical\n",
        "    max_pixel_value = 255.0\n",
        "    psnr_value = 20 * np.log10(max_pixel_value / np.sqrt(mse))\n",
        "    return psnr_value"
      ],
      "metadata": {
        "id": "bvIQylpbMBPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "l = [1, 111, 146, 179, 22, 23, 493, 547, 55, 665, 669, 748, 778, 780, 79]\n",
        "avg_psnr = 0\n",
        "avg_psnr1 = 0\n",
        "avg_ssim=0\n",
        "# Create a directory to store the predicted images\n",
        "output_dir = '/content/drive/MyDrive/LOWLIGHT/predicted_40'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for x in l:\n",
        "    # Convert x to string\n",
        "    x_str = str(x)\n",
        "\n",
        "    # Construct paths using the index\n",
        "    high_path = f'/content/drive/MyDrive/LOWLIGHT/lol_dataset/eval15/high/{x}.png'\n",
        "    low_path = f'/content/drive/MyDrive/LOWLIGHT/lol_dataset/eval15/low/{x}.png'\n",
        "\n",
        "    #print(f\"High Path: {high_path}\")\n",
        "    #print(f\"Low Path: {low_path}\")\n",
        "\n",
        "\n",
        "    # Load the input image (make sure it's preprocessed accordingly)\n",
        "    input_image1 = cv2.imread(high_path)\n",
        "\n",
        "    # Load the input image (make sure it's preprocessed accordingly)\n",
        "    input_image = cv2.imread(low_path)\n",
        "    input_image = input_image / 255.0\n",
        "\n",
        "    # Assume 'enlighten_net' is a pre-trained model for image enhancement\n",
        "    predicted_image = model.predict(np.expand_dims(input_image, axis=0))\n",
        "\n",
        "    # Post-processing (e.g., convert to the original scale)\n",
        "    predicted_image = (predicted_image[0] * 255).astype('uint8')\n",
        "    # Save the predicted image in the output directory\n",
        "    output_path = os.path.join(output_dir,f'{x}.png')\n",
        "    cv2.imwrite(output_path, predicted_image)\n",
        "\n",
        "    # Calculate PSNR\n",
        "    psnr_value = psnr(input_image1, predicted_image)\n",
        "    psnr_value1 = psnr1(input_image1, predicted_image)\n",
        "    #print(f\"PSNR Value for index {x}: {psnr_value} dB\")\n",
        "\n",
        "    # Accumulate PSNR values for averaging\n",
        "    avg_psnr += psnr_value\n",
        "    avg_psnr1 += psnr_value1\n",
        "    # Calculate SSIM\n",
        "    ssim_value = calculate_ssim(predicted_image, input_image1)\n",
        "\n",
        "    #print(f\"SSIM Value for index {x}: {ssim_value}\")\n",
        "\n",
        "    # Accumulate SSIM values for averaging\n",
        "    avg_ssim += ssim_value\n",
        "\n",
        "# Calculate average PSNR\n",
        "avg_psnr /= len(l)\n",
        "avg_psnr1 /= len(l)\n",
        "avg_ssim /= len(l)\n",
        "\n",
        "print(f\"Average PSNR: {avg_psnr} dB\")\n",
        "print(f\"Average PSNR: {avg_psnr1} dB\")\n",
        "print(f\"Average ssim: {avg_ssim } dB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE3klWlTMDhu",
        "outputId": "8ebacfa7-989f-4a7e-ba5c-1f64b6e3554a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Average PSNR: 17.95315039692469 dB\n",
            "Average PSNR: 28.175995183182764 dB\n",
            "Average ssim: 0.6951007344138376 dB\n"
          ]
        }
      ]
    }
  ]
}